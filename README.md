# Udacity Natural Language Processing Nanodegree

![Certificate](place_holder.png)

## Overview
|Official Duration|Projects|
|:-:|-|
|9 Feb - 13 Apr 2020|<ul><li>Part of Speech Tagging</li><li>Machine Translation</li><li>DNN Speech Recogniser</li></ul>|

## Projects
### 1. Part of Speech Tagging:
- **Project Overview:** Use the Pomegranate library to build a hidden Markov model for part of speech tagging with a universal tagset.

### 2. Machine Translation:
- **Project Overview:** Build a deep neural network that functions as part of an end-to-end machine translation pipeline. The completed pipeline accepts English text as input and return the French translation.

### 3. Deep Neural Network Speech Recogniser:
- **Project Overview:** Build a deep neural network that functions as part of an end-to-end automatic speech recognition (ASR) pipeline! 
- **Project Highlights:** 
  - Investigate the LibriSpeech dataset that will be used to train and evaluate your models. 
  - Convert any raw audio to feature representations that are commonly used for ASR. 
  - Build neural networks that can map these audio features to transcribed text. 
  - Create and Test your own state-of-the-art models after learning about the basic types of layers that are often used for deep learning-based approaches to ASR.
- **Dataset**: [LibriSpeech dataset](http://www.openslr.org/12/)

## Course Contents:
- Introduction to Natural Language Processing:
  - NLP Pipeline.
  - Text Processing: Prepare text obtained from different sources for further processing by **cleaning, normalising and splitting it into individual words or tokens**.
  - Build a **Spam Classifier** using **Naive Bayes**.
  - **Part of Speech Tagging** with **Hidden Markove Models**.
- Computing with Natural Language:
  - Feature extraction and embeddings: Transform text using methods like **Bag-of-Words**, **TF-IDF**, **Word2Vec**, and **GloVE** to extract features that you can use in machine learning models.
  - Topic modelling: Split a collection of documents into topics using **Latent Dirichlet Analysis (LDA)**.
  - Sentiment Analysis: Predict sentiment in text using **RNN**.
  - Sequence to Sequence: Generate one sequence from another sequence using specific architecture of RNNs.
  - Deep Learning Attention: Basic implementation of Attention.
  - RNN Keras Lab.
  - Cloud Computing Setup: Configure remote environment for GPU-accelerated training.
- Communicating with Natural Language:
  - Intro to Voice User Interfaces: Get acquainted with the principles and applications of VUI, and get introduced to Alexa skills.
  - Build your own Alexa skill and deploy it.
  - Speech Recognition: Learn how an ASR pipeline works.
